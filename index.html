<!DOCTYPE html>
<html lang="en">
  <head>
      <meta charset="UTF-8">
      <link rel="stylesheet" href="main.css">
      <link rel="icon" type="image/x-icon" href="assets/digit.png">
      <title>advnav</title>
  </head>
  <body>


    <div id="title_slide">
        <div class="title_left">
            <h1>Iterative Adversarial Learning with Chaser Agents <br> for Time-efficient Crowd-aware Navigation</h1>
        	<!-- Repo buttons (place right after the main <h1>) -->
			<div class="pill-links">
			  <a class="pill-link" href="https://github.com/tohoku-neurobotics/AdvNav"
			     target="_blank" rel="noopener noreferrer" aria-label="Open AdvNav GitHub repository">
			    <!-- GitHub icon (SVG) -->
			    <svg viewBox="0 0 24 24" aria-hidden="true" focusable="false">
			      <path d="M12 .5a11.5 11.5 0 0 0-3.64 22.42c.58.11.79-.25.79-.56v-2.06c-3.22.7-3.9-1.38-3.9-1.38-.53-1.35-1.28-1.71-1.28-1.71-1.05-.72.08-.7.08-.7 1.16.08 1.77 1.2 1.77 1.2 1.03 1.77 2.7 1.26 3.36.96.11-.75.4-1.26.72-1.55-2.57-.29-5.27-1.29-5.27-5.73 0-1.27.46-2.3 1.2-3.11-.12-.29-.52-1.47.12-3.06 0 0 .98-.31 3.2 1.19a11.1 11.1 0 0 1 5.83 0c2.22-1.5 3.2-1.19 3.2-1.19.64 1.59.24 2.77.12 3.06.75.81 1.2 1.84 1.2 3.11 0 4.45-2.71 5.44-5.29 5.72.41.36.78 1.07.78 2.16v3.2c0 .31.21.68.8.56A11.5 11.5 0 0 0 12 .5z"/>
			    </svg>
			    <span>Code Repo</span>
			  </a>
			</div>


			<div class="box alt">
			  <div class="row uniform">
			    <div class="4u">
			      <a href="https://github.com/stilrmy" target="_blank" rel="noopener noreferrer">
			        Tianjian Yuan<sup>*</sup>
			      </a>
			    </div>
			    <div class="4u">
			      <a href="https://www.weizhu996.com/" target="_blank" rel="noopener noreferrer">
			        Zhu Wei<sup>*</sup>
			      </a>
			    </div>
			    <div class="4u">
			      <a href="https://neuro.mech.tohoku.ac.jp/" target="_blank" rel="noopener noreferrer">
			        Hayashibe Mitsuhiro<sup>*</sup>
			      </a>
			    </div>
			  </div>
			</div>
			
			<div class="gatech">
			  <p><sup>*</sup>Neuro-Robotics Laboratory, Department of Robotics, Graduate School of Engineering, Tohoku University, Sendai 980-8577, Japan</p>
			</div>


            <br>

            <div id="abstract" class="grid-container">
                <p>
                  This paper addresses the challenge of safe and efficient crowd navigation for autonomous robots in dynamic environments. 
									Existing methods struggle in scenarios with unpredictable or obstructive pedestrian behaviors. These limitations raise serious 
									safety and efficiency concerns in real-world deployments. To improve navigation robustness and efficiency, we propose an adversarial 
									deep reinforcement learning (DRL) framework that simulates competitive pedestrian behaviors through a chaser agent. In addition, we further 
									introduce an ensemble agent that dynamically selects policies based on real-time observations, enhancing generalization across diverse scenarios.
									Extensive simulation results demonstrate enhanced navigation performance in terms of success rate and navigation efficiency when using our framework.
									Additionally, the ensemble agent further improves stability and overall generalizability across various environments. Real-world experiments 
									validate the approach and demonstrate the potential for sim-to-real transfer. 
                </p>
            </div>
        </div>
    </div>
    <hr class="rounded">
    
    <div id="overview">

        <h1>System architecture</h1>

        <p>
          In this paper, we introduce an adversarial reinforcement learning framework that improves safe and time-efficient crowd navigation
          by training with competitive chaser agents and an ensemble strategy. More specifically, the framework starts with pre-training a
          navigator agent in a non-adversarial environment to acquire basic navigation skills. We then introduce a reinforcement learningâ€“based
          chaser agent that creates competitive scenarios, forcing the navigator to adapt. To ensure stable performance across diverse
          environments, we further design an ensemble agent that dynamically selects between models trained in different iterations. After
          pre-training, the navigator and chaser are trained alternately under adversarial conditions. This iterative process allows both agents
          to exploit weaknesses and gradually improve their strategies, ultimately producing stronger and more robust navigation policies.
        </p>

        <div style="display: flex; justify-content: center;">
          <iframe 
            width="560" 
            height="315" 
            src="https://www.youtube.com/embed/uOsFafqcxEs?autoplay=1&mute=1" 
            frameborder="0" 
            allow="autoplay; encrypted-media" 
            allowfullscreen>
          </iframe>
        </div>

        <h1>Simulation benchmark in MuJoCo</h1>
        <p>
          Initially, we train and test our navigation policy in a physics-based simulator MuJoCo, using a full-body bipedal robot and a full-order 
          dynamics. Simulatioin comparisons demonstrate the effectiveness of our social navigation pipeline for bipedal robots.
        </p>

        <div style="display: flex; justify-content: center;">
          <iframe 
            width="560" 
            height="315" 
            src="https://www.youtube.com/embed/DsfEIVZ708A?autoplay=1&mute=1" 
            frameborder="0" 
            allow="autoplay; encrypted-media" 
            allowfullscreen>
          </iframe>
        </div>

        <h1>Simulation in complex scenario</h1>
        <p>
          We deploy our policy into a more complex simulation scenarios, further indicating that our navigation policy enables the bipedal 
          robot to adapt to complex and interactive scenarios integrated with pedestrian emotions.
        </p>

        <div style="display: flex; justify-content: center;">
          <iframe 
            width="560" 
            height="315" 
            src="https://www.youtube.com/embed/IpVLqscL89o?autoplay=1&mute=1" 
            frameborder="0" 
            allow="autoplay; encrypted-media" 
            allowfullscreen>
          </iframe>
        </div>

        <h1>Realworld experiments</h1>
        <p>
          Finally, we validated our approach in real-world scenarios using a mobile robot equipped with LiDAR and depth cameras, demonstrating
          the sim-to-real potential of our adversarial reinforcement learning framework.
        </p>
        
        <div style="display: flex; justify-content: center;">
          <iframe 
            width="560" 
            height="315" 
            src="https://www.youtube.com/embed/KnCzS2p8oLc?autoplay=1&mute=1" 
            frameborder="0" 
            allow="autoplay; encrypted-media" 
            allowfullscreen>
          </iframe>
        </div>

        <script>
          document.addEventListener("DOMContentLoaded", function() {
              document.querySelectorAll(".autoplay-video").forEach(function(iframe) {
                  iframe.src = iframe.getAttribute("data-src"); // Dynamically set the `src`
              });
          });
          </script>
       
        <h1>BibTeX</h1>
         <p class="bibtex">
            @article{zhu2025emobipednav,<br>
            &nbsp;&nbsp;title={EmoBipedNav: Emotion-aware Social Navigation for Bipedal Robots with Deep Reinforcement Learning},<br>
            &nbsp;&nbsp;author={Wei Zhu, Abirath Raju, Abdulaziz Shamsah, Anqi Wu, Seth Hutchinson, and Ye Zhao},<br>
            &nbsp;&nbsp;journal={arXiv preprint arXiv:2503.12538}<br>
            &nbsp;&nbsp;year={2025},<br>
            }
        </p>

      
       

        <div class="footer">
          <p>This website was developed based on <a href="https://github.com/learning-humanoid-locomotion/learning-humanoid-locomotion.github.io" target="_blank">learning-humanoid-locomotion</a></p>
      </div>
      
    </div>
    <script type="text/javascript">
        /* https://stackoverflow.com/questions/3027707/how-to-change-the-playing-speed-of-videos-in-html5 */
        document.querySelector('video').defaultPlaybackRate = 1.0;
        document.querySelector('video').play();

        var videos =document.querySelectorAll('video');
        for (var i=0;i<1;i++)
        {
            videos[i].playbackRate = 1.0;
        }
    </script>
    <script>
        /* https://stackoverflow.com/questions/21163756/html5-and-javascript-to-play-videos-only-when-visible */
        var videos = document.getElementsByTagName("video");

        function checkScroll() {
            var fraction = 0.5; // Play when 70% of the player is visible.

            for(var i = 0; i < 1; i++) {  // only apply to the first video

                var video = videos[i];

                var x = video.offsetLeft, y = video.offsetTop, w = video.offsetWidth, h = video.offsetHeight, r = x + w, //right
                    b = y + h, //bottom
                    visibleX, visibleY, visible;

                visibleX = Math.max(0, Math.min(w, window.pageXOffset + window.innerWidth - x, r - window.pageXOffset));
                visibleY = Math.max(0, Math.min(h, window.pageYOffset + window.innerHeight - y, b - window.pageYOffset));

                visible = visibleX * visibleY / (w * h);

                if (visible > fraction) {
                    video.play();
                } else {
                    video.pause();
                }

            }

        }
        window.addEventListener('scroll', checkScroll, false);
        window.addEventListener('resize', checkScroll, false);
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            // Function to check if the user is on a mobile device
            function isMobileDevice() {
                return /Mobi|Android/i.test(navigator.userAgent);
            }
            // If the user is on a mobile device, disable autoplay
            if (isMobileDevice()) {
                const videos = document.querySelectorAll('video');
                videos.forEach(video => {
                    video.autoplay = false;
                    video.controls = true;
                });
            }
        });
    </script>
    <script src="https://d3e54v103j8qbb.cloudfront.net/js/jquery-3.5.1.min.dc5e7f18c8.js?site=51e0d73d83d06baa7a00000f"
            type="text/javascript" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
            crossorigin="anonymous"></script>
    <script src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/js/webflow.fd002feec.js"
            type="text/javascript"></script>
  </body>

</html>
